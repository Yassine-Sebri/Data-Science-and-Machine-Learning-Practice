{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Ignore useless warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "# Essentials\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import RidgeCV, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from pystacknet.pystacknet import StackNetRegressor\n",
    "\n",
    "# Stats\n",
    "from scipy.stats import skew, norm\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "\n",
    "# Misc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the dataset as a dataframe\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Check the target distribution \n",
    "sns.distplot(train['target'] , fit=norm, color=\"b\");\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Finding numeric features\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numeric = []\n",
    "for i in train.columns:\n",
    "    if train[i].dtype in numeric_dtypes:\n",
    "        if i in []: # categorical features with numeric values\n",
    "            pass\n",
    "        else:\n",
    "            numeric.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split features and labels\n",
    "train_labels = train['target'].reset_index(drop=True)\n",
    "train_features = train.drop(['target'], axis=1)\n",
    "test_features = test\n",
    "\n",
    "# Combine train and test features in order to apply the feature transformation pipeline to the entire dataset\n",
    "all_features = pd.concat([train_features, test_features]).reset_index(drop=True)\n",
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# determine the threshold for missing values\n",
    "def percent_missing(df):\n",
    "    data = pd.DataFrame(df)\n",
    "    df_cols = list(pd.DataFrame(data))\n",
    "    dict_x = {}\n",
    "    for i in range(0, len(df_cols)):\n",
    "        dict_x.update({df_cols[i]: round(data[df_cols[i]].isnull().mean()*100,2)})\n",
    "    \n",
    "    return dict_x\n",
    "\n",
    "missing = percent_missing(all_features)\n",
    "df_miss = sorted(missing.items(), key=lambda x: x[1], reverse=True)\n",
    "print('Percent of missing data')\n",
    "df_miss[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Some of the non-numeric predictors might be stored as numbers; convert them into strings\n",
    "all_features['feature'] = all_features['feature'].astype(str)\n",
    "\n",
    "\n",
    "def handle_missing(features):\n",
    "    objects = []\n",
    "    for i in features.columns:\n",
    "        if features[i].dtype == object:\n",
    "            objects.append(i)\n",
    "    features.update(features[objects].fillna('None'))\n",
    "        \n",
    "    # And we do the same thing for numerical features, but this time with 0s\n",
    "    numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    numeric = []\n",
    "    for i in features.columns:\n",
    "        if features[i].dtype in numeric_dtypes:\n",
    "            numeric.append(i)\n",
    "    features.update(features[numeric].fillna(0))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Let's make sure we handled all the missing values\n",
    "missing = percent_missing(all_features)\n",
    "df_miss = sorted(missing.items(), key=lambda x: x[1], reverse=True)\n",
    "print('Percent of missing data')\n",
    "df_miss[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Find skewed numerical features\n",
    "skew_features = all_features[numeric].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "\n",
    "high_skew = skew_features[skew_features > 0.5]\n",
    "skew_index = high_skew.index\n",
    "\n",
    "print(\"There are {} numerical features with Skew > 0.5 :\".format(high_skew.shape[0]))\n",
    "skewness = pd.DataFrame({'Skew' :high_skew})\n",
    "skew_features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize skewed features\n",
    "for i in skew_index:\n",
    "    all_features[i] = boxcox1p(all_features[i], boxcox_normmax(all_features[i] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "all_features = pd.get_dummies(all_features).reset_index(drop=True)\n",
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Recreate training and test sets\n",
    "\n",
    "X = all_features.iloc[:len(train_labels), :]\n",
    "\n",
    "X_test = all_features.iloc[len(train_labels):, :]\n",
    "\n",
    "X.shape, train_labels.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setup cross validation folds\n",
    "kf = KFold(n_splits=12, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define error metrics\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def cv_rmse(model, X=X):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, train_labels, scoring=\"neg_mean_squared_error\", cv=kf))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Light Gradient Boosting Regressor\n",
    "lightgbm = LGBMRegressor(objective='regression', \n",
    "                       num_leaves=6,\n",
    "                       learning_rate=0.01, \n",
    "                       n_estimators=7000,\n",
    "                       max_bin=200, \n",
    "                       bagging_fraction=0.8,\n",
    "                       bagging_freq=4, \n",
    "                       bagging_seed=8,\n",
    "                       feature_fraction=0.2,\n",
    "                       feature_fraction_seed=8,\n",
    "                       min_sum_hessian_in_leaf = 11,\n",
    "                       verbose=-1,\n",
    "                       random_state=42)\n",
    "\n",
    "# XGBoost Regressor\n",
    "xgboost = XGBRegressor(learning_rate=0.01,\n",
    "                       n_estimators=6000,\n",
    "                       max_depth=4,\n",
    "                       min_child_weight=0,\n",
    "                       gamma=0.6,\n",
    "                       subsample=0.7,\n",
    "                       colsample_bytree=0.7,\n",
    "                       objective='reg:linear',\n",
    "                       nthread=-1,\n",
    "                       scale_pos_weight=1,\n",
    "                       seed=27,\n",
    "                       reg_alpha=0.00006,\n",
    "                       random_state=42)\n",
    "\n",
    "# Ridge Regressor\n",
    "ridge_alphas = [1e-15, 1e-10, 1e-8, 9e-4, 7e-4, 5e-4, 3e-4, 1e-4, 1e-3, 5e-2, 1e-2, 0.1, 0.3, 1, 3, 5, 10, 15, 18, 20, 30, 50, 75, 100]\n",
    "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=ridge_alphas, cv=kf))\n",
    "\n",
    "# Support Vector Regressor\n",
    "svr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003))\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "gbr = GradientBoostingRegressor(n_estimators=6000,\n",
    "                                learning_rate=0.01,\n",
    "                                max_depth=4,\n",
    "                                max_features='sqrt',\n",
    "                                min_samples_leaf=15,\n",
    "                                min_samples_split=10,\n",
    "                                loss='huber',\n",
    "                                random_state=42)  \n",
    "\n",
    "# Random Forest Regressor\n",
    "rf = RandomForestRegressor(n_estimators=1200,\n",
    "                          max_depth=15,\n",
    "                          min_samples_split=5,\n",
    "                          min_samples_leaf=5,\n",
    "                          max_features=None,\n",
    "                          oob_score=True,\n",
    "                          random_state=42)\n",
    "\n",
    "# Stack up all the models above, optimized using xgboost\n",
    "stack_gen = StackingCVRegressor(regressors=(xgboost, lightgbm, svr, ridge, gbr, rf),\n",
    "                                meta_regressor=xgboost,\n",
    "                                use_features_in_secondary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scores = {}\n",
    "\n",
    "score = cv_rmse(lightgbm)\n",
    "print(\"lightgbm: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['lgb'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score = cv_rmse(xgboost)\n",
    "print(\"xgboost: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['xgb'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score = cv_rmse(svr)\n",
    "print(\"SVR: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['svr'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score = cv_rmse(ridge)\n",
    "print(\"ridge: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['ridge'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score = cv_rmse(rf)\n",
    "print(\"rf: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['rf'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score = cv_rmse(gbr)\n",
    "print(\"gbr: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['gbr'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('stack_gen')\n",
    "stack_gen_model = stack_gen.fit(np.array(X), np.array(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('lightgbm')\n",
    "lgb_model_full_data = lightgbm.fit(X, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('xgboost')\n",
    "xgb_model_full_data = xgboost.fit(X, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Svr')\n",
    "svr_model_full_data = svr.fit(X, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Ridge')\n",
    "ridge_model_full_data = ridge.fit(X, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('RandomForest')\n",
    "rf_model_full_data = rf.fit(X, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('GradientBoosting')\n",
    "gbr_model_full_data = gbr.fit(X, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Blend models in order to make the final predictions more robust to overfitting\n",
    "def blended_predictions(X):\n",
    "    return ((0.1 * ridge_model_full_data.predict(X)) + \\\n",
    "            (0.2 * svr_model_full_data.predict(X)) + \\\n",
    "            (0.1 * gbr_model_full_data.predict(X)) + \\\n",
    "            (0.1 * xgb_model_full_data.predict(X)) + \\\n",
    "            (0.1 * lgb_model_full_data.predict(X)) + \\\n",
    "            (0.05 * rf_model_full_data.predict(X)) + \\\n",
    "            (0.35 * stack_gen_model.predict(np.array(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get final precitions from the blended model\n",
    "blended_score = rmsle(train_labels, blended_predictions(X))\n",
    "scores['blended'] = (blended_score, 0)\n",
    "print('RMSLE score on train data:')\n",
    "print(blended_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read in sample_submission dataframe\n",
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "submission.shape\n",
    "\n",
    "# Append predictions from blended models\n",
    "submission.iloc[:,1] = np.floor(np.expm1(blended_predictions(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "FOLDS=4\n",
    "METRIC=\"rmse\"\n",
    "RESTACKING=False\n",
    "RETRAIN=True\n",
    "SEED=12345\n",
    "VERBOSE=1\n",
    "\n",
    "models=[\n",
    "    #1ST level #\n",
    "    \n",
    "    [Ridge(alpha=0.1, normalize=True, random_state=1234)],\n",
    "    \n",
    "        #2ND level # \n",
    "\n",
    "        [Ridge(alpha=0.1, normalize=True, random_state=1234)],    \n",
    "\n",
    "]\n",
    "\n",
    "#MODEL STATEMENT\n",
    "model=StackNetRegressor(models, metric=METRIC, folds=FOLDS,\n",
    "    restacking=RESTACKING, use_retraining=RETRAIN, \n",
    "    random_state=SEED, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "def keras_model():\n",
    "    # Here's a Deep Dumb MLP (DDMLP)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=10))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    # we'll use categorical xent for the loss, and RMSprop as the optimizer\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "KerasRegressor(build_fn=keras_model, epochs=10, batch_size=15, verbose=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Algorithms and Data Structures)",
   "language": "python",
   "name": "pycharm-58a059a8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
